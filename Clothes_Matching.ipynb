{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.misc import imread, imresize\n",
    "sys.path.append(\"tensorflow-vgg\")\n",
    "import vgg16\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "from os import listdir\n",
    "import os\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "\n",
    "rcParams['figure.figsize'] = 8, 10\n",
    "\n",
    "def ls_function(mypath):\n",
    "    return [f for f in listdir(mypath) if not f == '.DS_Store']\n",
    "\n",
    "def load_images_as_batch(paths):\n",
    "    return np.vstack([imresize(imread(p), (224,224,3))[None,...] for p in paths])\n",
    "\n",
    "\n",
    "#Get paths to images\n",
    "path_to_images = \"/media/data_cifs/nyu/img/\"\n",
    "all_paths = []\n",
    "for l in tqdm(ls_function(path_to_images)):\n",
    "    try:\n",
    "        all_paths += [\"{}/{}/{}\".format(path_to_images, l, f) for f in ls_function(\"{}/{}\".format(path_to_images, l))]\n",
    "    except OSError as e:\n",
    "        continue\n",
    "all_paths = np.random.permutation(all_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dshieble/Clothing_Experiments/tensorflow-vgg/vgg16.npy\n",
      "npy file loaded\n",
      "build model started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build model finished: 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 810, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tqdm/_tqdm.py\", line 102, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/usr/lib/python2.7/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "\n",
      "  0%|          | 1/400 [00:17<1:58:11, 17.77s/it]\u001b[A\n",
      "  0%|          | 2/400 [00:20<1:28:19, 13.31s/it]\u001b[A\n",
      "  1%|          | 3/400 [00:23<1:08:11, 10.31s/it]\u001b[A\n",
      "  1%|          | 4/400 [00:27<54:09,  8.21s/it]  \u001b[A\n",
      "  1%|▏         | 5/400 [00:30<44:06,  6.70s/it]\u001b[A\n",
      "  2%|▏         | 6/400 [00:33<36:50,  5.61s/it]\u001b[A\n",
      "  2%|▏         | 7/400 [00:36<31:43,  4.84s/it]\u001b[A\n",
      "  2%|▏         | 8/400 [00:39<28:23,  4.35s/it]\u001b[A\n",
      "  2%|▏         | 9/400 [00:42<25:15,  3.87s/it]\u001b[A\n",
      "  2%|▎         | 10/400 [00:45<23:29,  3.61s/it]\u001b[A\n",
      "  3%|▎         | 11/400 [00:48<21:52,  3.37s/it]\u001b[A\n",
      "  3%|▎         | 12/400 [00:51<22:01,  3.41s/it]\u001b[A\n",
      "  3%|▎         | 13/400 [00:54<21:16,  3.30s/it]\u001b[A\n",
      "  4%|▎         | 14/400 [00:57<20:35,  3.20s/it]\u001b[A\n",
      "  4%|▍         | 15/400 [01:01<20:29,  3.19s/it]\u001b[A\n",
      "  4%|▍         | 16/400 [01:05<22:35,  3.53s/it]\u001b[A\n",
      "  4%|▍         | 17/400 [01:08<20:56,  3.28s/it]\u001b[A\n",
      "  4%|▍         | 18/400 [01:10<20:08,  3.16s/it]\u001b[A\n",
      "  5%|▍         | 19/400 [01:13<19:21,  3.05s/it]\u001b[A\n",
      "  5%|▌         | 20/400 [01:16<19:14,  3.04s/it]\u001b[A\n",
      "  5%|▌         | 21/400 [01:19<19:05,  3.02s/it]\u001b[A\n",
      "  6%|▌         | 22/400 [01:22<18:42,  2.97s/it]\u001b[A\n",
      "  6%|▌         | 23/400 [01:25<19:26,  3.09s/it]\u001b[A\n",
      "  6%|▌         | 24/400 [01:29<20:12,  3.22s/it]\u001b[A\n",
      "  6%|▋         | 25/400 [01:32<20:38,  3.30s/it]\u001b[A\n",
      "  6%|▋         | 26/400 [01:36<20:24,  3.27s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "#Generate Feature Vectors\n",
    "device = \"/gpu:2\" #device to run on. Set to \"/cpu:0\" if your machine isn't equipped with a CUDA-capable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=device.split(\":\")[-1][0] #Enfore that only the specified device is used\n",
    "\n",
    "processed_paths = [] #List of image paths\n",
    "processed_feature_vectors = [] #Feature vector for each path. In a real application this won't fit in memory. \n",
    "batch_size = 50 #Number of images to run at each step\n",
    "#Maximum number of images in the \"dataset\". Performance will improve and things will slow down as this number goes up\n",
    "num_images = 20000 \n",
    "\n",
    "tf.reset_default_graph() #Clear the tensorflow graph\n",
    "x = tf.placeholder(tf.float32, (None, 224, 224, 3), name=\"x\") #Tensorflow placeholder variable\n",
    "with tf.device(device):\n",
    "    #build the model\n",
    "    vgg = vgg16.Vgg16()\n",
    "    vgg.build(x)\n",
    "    sess = tf.InteractiveSession(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    #Run each batch of images through the model and generate the feature vectors\n",
    "    for i in tqdm(range(0, num_images, batch_size)):\n",
    "        batch = load_images_as_batch(all_paths[i:i+batch_size])\n",
    "        feature_vectors = sess.run(vgg.fc7, feed_dict={x:batch})\n",
    "        processed_paths += list(all_paths[i:i+batch_size])\n",
    "        processed_feature_vectors += list(feature_vectors)\n",
    "\n",
    "#Build the nearest neighbor tree of feature vectors\n",
    "tree = KDTree(np.vstack(processed_feature_vectors))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Put the path to the query image here (the image that you would like to find similar images to)\n",
    "image_path = '/media/data_cifs/nyu/img//Diamond_Print_Skater_Dress/img_00000002.jpg'\n",
    "\n",
    "query_image = load_images_as_batch([image_path])\n",
    "feature_vector = sess.run(vgg.fc7, feed_dict={x:query_image})\n",
    "_, inds = tree.query(feature_vector, k=9) \n",
    "\n",
    "results_images = load_images_as_batch([processed_paths[ind] for ind in inds[0]])\n",
    "plt.figure()\n",
    "plt.title(\"Query Image\")\n",
    "plt.imshow(query_image[0])\n",
    "plt.figure()\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.title(\"Results Image\")\n",
    "    plt.imshow(results_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fc7/BiasAdd:0' shape=(?, 4096) dtype=float32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
